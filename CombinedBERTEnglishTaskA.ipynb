{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3750,
     "status": "ok",
     "timestamp": 1584289880737,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "BeF_gt3eup5q",
    "outputId": "4cdd21da-6120-4378-e450-f7cf58eedcaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3877,
     "status": "ok",
     "timestamp": 1584289883595,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "XPg-Fhc6Kbxj",
    "outputId": "b3c76065-b547-4238-8d03-4caf68cfa18d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7337,
     "status": "ok",
     "timestamp": 1584289891900,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "BvlH2xtxKl0Q",
    "outputId": "374e3cc5-b342-407c-f677-d7b1a6c6cc44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 501kB 5.1MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 870kB 15.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0MB 24.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.7MB 46.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=69398682ef59886f615b791766a9f12f28e16dbafd943451a13ba2ac66a8e42d\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1900,
     "status": "ok",
     "timestamp": 1584289916800,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "pZm6DIbsKrVg",
    "outputId": "2ad35c4e-11ce-4434-c218-590b0356bf09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next part</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more v...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0                                          Next part   NAG\n",
       "1                 Iii8mllllllm\\nMdxfvb8o90lplppi0005   NAG\n",
       "2  ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more v...   NAG\n",
       "3  What the fuck was this? I respect shwetabh and...   NAG\n",
       "4  Concerned authorities should bring arundathi R...   NAG"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/content/drive/My Drive/MinorProject/eng_train.csv\")\n",
    "df=df.drop(columns=['ID','Sub-task B'])\n",
    "df=df.rename(columns={\"Sub-task A\":\"label\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qNAGy9TX5Ws"
   },
   "outputs": [],
   "source": [
    "# df2=pd.read_csv('/content/drive/My Drive/MinorProject/hin_dev.csv')\n",
    "# df2=df2.drop(columns=['ID','Sub-task B'])\n",
    "# df2=df2.rename(columns={\"Sub-task A\":\"label\"})\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1958,
     "status": "ok",
     "timestamp": 1584289948102,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "wb6fM_N8bgU7",
    "outputId": "5274f056-50d3-4e78-fb9c-e1e9eac06337"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The quality of re made now makes me think it i...</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@siva \\nHow is ur mother???\\nHow is ur wife???...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Also see ....hw ur RSS activist caught in Burk...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the death of 2 jawans in LOC CROSS FIRING\\n...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modi ho ya Manmohan singh saala yeh log kuch n...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0  The quality of re made now makes me think it i...   CAG\n",
       "1  @siva \\nHow is ur mother???\\nHow is ur wife???...   NAG\n",
       "2  Also see ....hw ur RSS activist caught in Burk...   NAG\n",
       "3  On the death of 2 jawans in LOC CROSS FIRING\\n...   NAG\n",
       "4  Modi ho ya Manmohan singh saala yeh log kuch n...   OAG"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_csv('/content/drive/My Drive/MinorProject/agr_en_dev.csv',names=['File_ID','Text','label'])\n",
    "df3=df3.drop(columns=['File_ID'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1584289972646,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "2lgK3TUCdDsi",
    "outputId": "7e8f99cb-ed31-40c8-a45f-436ec35cce1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If government of india don't take strict actio...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So now we know. The women should be under the ...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§ó‡§¶‡•ç‡§¶‡§æ‡§∞‡•ã ‡§§‡•Å‡§Æ‡§∏‡•á ‡§π‡•Ä ‡§§‡•ã ‡§ñ‡§§‡§∞‡§æ ‡§π‡•à ‡§Ö‡§¨‡§ï‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§æ‡§´ ‡§π‡•ã ‡§ú‡§æ‡§ì‡§ó‡•á</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you think markets are gonna be sideways til...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jago Urjut Jago....\\nSave common people from\\n...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0  If government of india don't take strict actio...   NAG\n",
       "1  So now we know. The women should be under the ...   NAG\n",
       "2  ‡§ó‡§¶‡•ç‡§¶‡§æ‡§∞‡•ã ‡§§‡•Å‡§Æ‡§∏‡•á ‡§π‡•Ä ‡§§‡•ã ‡§ñ‡§§‡§∞‡§æ ‡§π‡•à ‡§Ö‡§¨‡§ï‡•Ä ‡§¨‡§æ‡§∞ ‡§∏‡§æ‡§´ ‡§π‡•ã ‡§ú‡§æ‡§ì‡§ó‡•á   NAG\n",
       "3  Do you think markets are gonna be sideways til...   NAG\n",
       "4  Jago Urjut Jago....\\nSave common people from\\n...   NAG"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.read_csv('/content/drive/My Drive/MinorProject/agr_en_fb_gold.csv',names=['File_ID','Text','label'])\n",
    "df4=df4.drop(columns=['File_ID'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1354,
     "status": "ok",
     "timestamp": 1584289995539,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "m7Mhf41xdQ3r",
    "outputId": "448d89e8-79aa-4c61-85e0-cfbfebdc7da0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6-0 hahahahahaha har ek pakistani ko yeh pic d...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sardanarohit :While entire nation is praying ...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shoaib: wahab riaz looks like johnson. kapil d...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ramraj cottons r. ashwin southindian , chennai...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#indvsuae jeet gaye... :) :) cmon starsports n...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0  6-0 hahahahahaha har ek pakistani ko yeh pic d...   NAG\n",
       "1  @sardanarohit :While entire nation is praying ...   OAG\n",
       "2  shoaib: wahab riaz looks like johnson. kapil d...   NAG\n",
       "3  ramraj cottons r. ashwin southindian , chennai...   NAG\n",
       "4  #indvsuae jeet gaye... :) :) cmon starsports n...   NAG"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.read_csv('/content/drive/My Drive/MinorProject/agr_en_tw_gold.csv',names=['File_ID','Text','label'])\n",
    "df5=df5.drop(columns=['File_ID'])\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2548,
     "status": "ok",
     "timestamp": 1584290033051,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "dY9zJ-mvCuho",
    "outputId": "2ec835c4-319e-410c-8a8d-1b38efbe3df5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well said sonu..you have courage to stand agai...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Most of Private Banks ATM's Like HDFC, ICICI e...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now question is, Pakistan will adhere to this?</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan is comprised of fake muslims who does...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>??we r against cow slaughter,so of course it w...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0  Well said sonu..you have courage to stand agai...   OAG\n",
       "1  Most of Private Banks ATM's Like HDFC, ICICI e...   NAG\n",
       "2     Now question is, Pakistan will adhere to this?   OAG\n",
       "3  Pakistan is comprised of fake muslims who does...   OAG\n",
       "4  ??we r against cow slaughter,so of course it w...   NAG"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.read_csv('/content/drive/My Drive/MinorProject/agr_en_train.csv',names=['File_ID','Text','label'])\n",
    "df6=df6.drop(columns=['File_ID'])\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1584290045288,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "l6HoezBKdgnd",
    "outputId": "f8c9d9ba-fe2c-4ce1-e254-ff0fee5af581"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21436, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([df,df3,df4,df5,df6])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1584290046850,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "VPgTp6uTMSYm",
    "outputId": "4efa147f-2225-498b-fa95-23f2a81125d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next part</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more v...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label\n",
       "0                                          Next part      2\n",
       "1                 Iii8mllllllm\\nMdxfvb8o90lplppi0005      2\n",
       "2  ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more v...      2\n",
       "3  What the fuck was this? I respect shwetabh and...      2\n",
       "4  Concerned authorities should bring arundathi R...      2"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'OAG': 0, 'CAG':1,'NAG':2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsm2ejSgLCPg"
   },
   "outputs": [],
   "source": [
    "sentences = df.Text.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1584290050143,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "56qGkZePL5r1",
    "outputId": "ed5760b5-a8cd-4fb7-e6ed-55dabaad2eaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Next part', 'Iii8mllllllm\\nMdxfvb8o90lplppi0005',\n",
       "       'ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more vedios like this',\n",
       "       ..., 'fabricated news', \"What's wrong with you secular idiots\",\n",
       "       'Looks like inevitable after all political hard ball dialogue coupled with diplomacy & arm twisting with international pressures produce little or no results.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1584290051639,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "uQzqBtunMEXT",
    "outputId": "7956b8c6-0660-4175-920b-d3ddb027bb97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "18f355f6996a4420aa1dec7da283e616",
      "01ace6adf4684de288bd637d2f34c920",
      "3c861433c6094e8a9a3373e5e266046c",
      "295602ce988c4923bf3f7f01b6f76751",
      "db97b4da1a804df083f4b393c5cc9bc1",
      "3e64a383e5094df292574039868448e6",
      "f2891d723a69430d9078588a000c5b75",
      "ce02619fe6354e75b8431dcf84847556"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2399,
     "status": "ok",
     "timestamp": 1584290054120,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "r7SnHXbKNG-4",
    "outputId": "7d4095d0-ce74-47a6-960d-34e91d0ff9d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f355f6996a4420aa1dec7da283e616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid‚Ä¶"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11222,
     "status": "ok",
     "timestamp": 1584290064015,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "g0cQ186VNYLn",
    "outputId": "8e3a7265-bd14-4216-8afc-c18c4e213a03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent, \n",
    "                        add_special_tokens = True,\n",
    "                   )\n",
    "    input_ids.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10018,
     "status": "ok",
     "timestamp": 1584290064020,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "YQm55nf7NnI3",
    "outputId": "d6f4a07e-97ee-46ad-f7ce-efa654e6ed7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  1651\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1204,
     "status": "ok",
     "timestamp": 1584290069949,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "FUWPE3qXN7jo",
    "outputId": "3b800de7-ca93-40a2-8280-3128169643a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 100\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q2plWstlOCzb"
   },
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PjHSmAYOHB5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=42, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXIeTWjvOQ-p"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijxbNY5wOUT6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a207545455954424b871b0c9d6b0c77c",
      "0f38ed5bb47748d39233b34cb4fa55a3",
      "eb16f15aa81c4fdbb4b32c812e23ab89",
      "42e04e9b02fa48779534244842a5c6c7",
      "ba5f40c5de964894a739fee78dd38208",
      "17f85ceaf6424513af0c284d1d4c85cb",
      "39e7a7a4527f4be08b882ded35783905",
      "0acb60a0611c4226bdcaa7c85912b5d9",
      "e378e57b9f2c48abbfaddb116faba4f3",
      "0fb4adb184b142c8b9561b96ec5a0f56",
      "6e1a295942b94359839996e52aa05830",
      "53db219efdf74e57bd629ec214cac13b",
      "4c49052583dd42c0b62c734aa5220b02",
      "099e836157634a57bff32d98cdd6aabc",
      "3acdc8649bd04051bc298b1f1b1ccf28",
      "a8cfb4ce32134df2ae156b217d7de3e6"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26749,
     "status": "ok",
     "timestamp": 1584290105212,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "-tU41xhhOY96",
    "outputId": "6155b7d6-75a3-4011-9515-16ced6294a3f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a207545455954424b871b0c9d6b0c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=‚Ä¶"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e378e57b9f2c48abbfaddb116faba4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_‚Ä¶"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 3, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1584290108373,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "0oHbBOoyOcnq",
    "outputId": "95ff8619-7664-4836-a664-42fb2c95fba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (3, 768)\n",
      "classifier.bias                                                 (3,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wg7AYs7ZOolL"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1T4L7XvOtdL"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifH3p_kUOwtb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sSwDDcaO0oq"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784460,
     "status": "ok",
     "timestamp": 1584290897498,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "0iZ11umBO3Vq",
    "outputId": "8ce5593f-63a2-4e1c-96a2-e313474557c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    603.    Elapsed: 0:00:13.\n",
      "  Batch    80  of    603.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    603.    Elapsed: 0:00:38.\n",
      "  Batch   160  of    603.    Elapsed: 0:00:51.\n",
      "  Batch   200  of    603.    Elapsed: 0:01:03.\n",
      "  Batch   240  of    603.    Elapsed: 0:01:16.\n",
      "  Batch   280  of    603.    Elapsed: 0:01:28.\n",
      "  Batch   320  of    603.    Elapsed: 0:01:41.\n",
      "  Batch   360  of    603.    Elapsed: 0:01:53.\n",
      "  Batch   400  of    603.    Elapsed: 0:02:06.\n",
      "  Batch   440  of    603.    Elapsed: 0:02:19.\n",
      "  Batch   480  of    603.    Elapsed: 0:02:31.\n",
      "  Batch   520  of    603.    Elapsed: 0:02:44.\n",
      "  Batch   560  of    603.    Elapsed: 0:02:56.\n",
      "  Batch   600  of    603.    Elapsed: 0:03:09.\n",
      "\n",
      "  Average training loss: 0.84\n",
      "  Training epcoh took: 0:03:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.63\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    603.    Elapsed: 0:00:13.\n",
      "  Batch    80  of    603.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    603.    Elapsed: 0:00:38.\n",
      "  Batch   160  of    603.    Elapsed: 0:00:50.\n",
      "  Batch   200  of    603.    Elapsed: 0:01:03.\n",
      "  Batch   240  of    603.    Elapsed: 0:01:15.\n",
      "  Batch   280  of    603.    Elapsed: 0:01:28.\n",
      "  Batch   320  of    603.    Elapsed: 0:01:40.\n",
      "  Batch   360  of    603.    Elapsed: 0:01:53.\n",
      "  Batch   400  of    603.    Elapsed: 0:02:06.\n",
      "  Batch   440  of    603.    Elapsed: 0:02:18.\n",
      "  Batch   480  of    603.    Elapsed: 0:02:31.\n",
      "  Batch   520  of    603.    Elapsed: 0:02:43.\n",
      "  Batch   560  of    603.    Elapsed: 0:02:56.\n",
      "  Batch   600  of    603.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    603.    Elapsed: 0:00:13.\n",
      "  Batch    80  of    603.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    603.    Elapsed: 0:00:38.\n",
      "  Batch   160  of    603.    Elapsed: 0:00:50.\n",
      "  Batch   200  of    603.    Elapsed: 0:01:03.\n",
      "  Batch   240  of    603.    Elapsed: 0:01:15.\n",
      "  Batch   280  of    603.    Elapsed: 0:01:28.\n",
      "  Batch   320  of    603.    Elapsed: 0:01:40.\n",
      "  Batch   360  of    603.    Elapsed: 0:01:53.\n",
      "  Batch   400  of    603.    Elapsed: 0:02:06.\n",
      "  Batch   440  of    603.    Elapsed: 0:02:18.\n",
      "  Batch   480  of    603.    Elapsed: 0:02:31.\n",
      "  Batch   520  of    603.    Elapsed: 0:02:43.\n",
      "  Batch   560  of    603.    Elapsed: 0:02:56.\n",
      "  Batch   600  of    603.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    603.    Elapsed: 0:00:13.\n",
      "  Batch    80  of    603.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    603.    Elapsed: 0:00:38.\n",
      "  Batch   160  of    603.    Elapsed: 0:00:50.\n",
      "  Batch   200  of    603.    Elapsed: 0:01:03.\n",
      "  Batch   240  of    603.    Elapsed: 0:01:15.\n",
      "  Batch   280  of    603.    Elapsed: 0:01:28.\n",
      "  Batch   320  of    603.    Elapsed: 0:01:40.\n",
      "  Batch   360  of    603.    Elapsed: 0:01:53.\n",
      "  Batch   400  of    603.    Elapsed: 0:02:06.\n",
      "  Batch   440  of    603.    Elapsed: 0:02:18.\n",
      "  Batch   480  of    603.    Elapsed: 0:02:31.\n",
      "  Batch   520  of    603.    Elapsed: 0:02:43.\n",
      "  Batch   560  of    603.    Elapsed: 0:02:56.\n",
      "  Batch   600  of    603.    Elapsed: 0:03:08.\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:03:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation took: 0:00:06\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "loss_values = []\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2764,
     "status": "ok",
     "timestamp": 1584290916924,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "P6LcOaGXPBo7",
    "outputId": "120f1536-ab09-404d-9af2-1006101aa81a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "plt.plot(loss_values, 'b-o')\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3482,
     "status": "ok",
     "timestamp": 1584290921143,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "UVzhAe8cS-Bv",
    "outputId": "873264a8-de2b-46f7-f61a-3867fcfa8681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 1,066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next part</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more v...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Concerned authorities should bring arundathi R...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label\n",
       "0                                          Next part      2\n",
       "1                 Iii8mllllllm\\nMdxfvb8o90lplppi0005      2\n",
       "2  ü§£ü§£üòÇüòÇü§£ü§£ü§£üòÇosm vedio ....keep it up...make more v...      2\n",
       "3  What the fuck was this? I respect shwetabh and...      2\n",
       "4  Concerned authorities should bring arundathi R...      2"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"/content/drive/My Drive/MinorProject/eng_dev.csv\")\n",
    "df1=df1.drop(columns=['ID','Sub-task B'])\n",
    "print('Number of test sentences: {:,}\\n'.format(df1.shape[0]))\n",
    "df1=df1.rename(columns={\"Sub-task A\":\"label\"})\n",
    "df1['label'] = df1['label'].map({'OAG': 0, 'CAG':1,'NAG':2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTAScmrfTFkB"
   },
   "outputs": [],
   "source": [
    "\n",
    "sentences = df1.Text.values\n",
    "labels = df1.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5019,
     "status": "ok",
     "timestamp": 1584290924971,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "n0IbWyQASypi",
    "outputId": "aba25da4-c04f-451a-c28c-9e09c1a8d739"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                                           )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "batch_size = 32  \n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5486,
     "status": "ok",
     "timestamp": 1584290926243,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "6aCboXtgTQb_",
    "outputId": "e7980d96-26c6-4fd1-a621-ac5495820eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 1,066 test sentences...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    "for batch in prediction_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_labels = batch  \n",
    "  with torch.no_grad():\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  predictions.append(logits) \n",
    "  true_labels.append(label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6459,
     "status": "ok",
     "timestamp": 1584290928189,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "Mt0JAwzVTb7W",
    "outputId": "2f26f69e-4fa9-4b20-ed2c-ada852265d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 27849 of 21436 (129.92%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5707,
     "status": "ok",
     "timestamp": 1584290928192,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "7dj6V-tpTguG",
    "outputId": "24bf7ed4-ad1d-4198-e76c-49fe0933d24f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf_set = []\n",
    "for i in range(len(true_labels)):\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  clf = classification_report(true_labels[i], pred_labels_i)                \n",
    "  clf_set.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5054,
     "status": "ok",
     "timestamp": 1584290928194,
     "user": {
      "displayName": "JITENDRA KUMAR",
      "photoUrl": "",
      "userId": "00441222890530056502"
     },
     "user_tz": -330
    },
    "id": "J62sxVGeTqMn",
    "outputId": "e7058f2d-e617-4701-eeb7-af6f88a89684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.64      0.51       113\n",
      "           1       0.31      0.38      0.34       117\n",
      "           2       0.91      0.83      0.87       836\n",
      "\n",
      "    accuracy                           0.76      1066\n",
      "   macro avg       0.55      0.61      0.57      1066\n",
      "weighted avg       0.80      0.76      0.77      1066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "clf= classification_report(flat_true_labels, flat_predictions)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhYGDUhDTvC3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPkPwbUBYd733uxFUiAOnO8",
   "collapsed_sections": [],
   "mount_file_id": "17hpwVkNjL_aQHqzCR0v_rw-4tCl58z_3",
   "name": "CombinedBERTEnglishTaskA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ace6adf4684de288bd637d2f34c920": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "099e836157634a57bff32d98cdd6aabc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0acb60a0611c4226bdcaa7c85912b5d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f38ed5bb47748d39233b34cb4fa55a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fb4adb184b142c8b9561b96ec5a0f56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17f85ceaf6424513af0c284d1d4c85cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18f355f6996a4420aa1dec7da283e616": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c861433c6094e8a9a3373e5e266046c",
       "IPY_MODEL_295602ce988c4923bf3f7f01b6f76751"
      ],
      "layout": "IPY_MODEL_01ace6adf4684de288bd637d2f34c920"
     }
    },
    "295602ce988c4923bf3f7f01b6f76751": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce02619fe6354e75b8431dcf84847556",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f2891d723a69430d9078588a000c5b75",
      "value": "100% 232k/232k [00:00&lt;00:00, 1.19MB/s]"
     }
    },
    "39e7a7a4527f4be08b882ded35783905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3acdc8649bd04051bc298b1f1b1ccf28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c861433c6094e8a9a3373e5e266046c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e64a383e5094df292574039868448e6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db97b4da1a804df083f4b393c5cc9bc1",
      "value": 231508
     }
    },
    "3e64a383e5094df292574039868448e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42e04e9b02fa48779534244842a5c6c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0acb60a0611c4226bdcaa7c85912b5d9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_39e7a7a4527f4be08b882ded35783905",
      "value": "100% 361/361 [00:00&lt;00:00, 9.09kB/s]"
     }
    },
    "4c49052583dd42c0b62c734aa5220b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "53db219efdf74e57bd629ec214cac13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8cfb4ce32134df2ae156b217d7de3e6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3acdc8649bd04051bc298b1f1b1ccf28",
      "value": "100% 440M/440M [00:12&lt;00:00, 34.4MB/s]"
     }
    },
    "6e1a295942b94359839996e52aa05830": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_099e836157634a57bff32d98cdd6aabc",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c49052583dd42c0b62c734aa5220b02",
      "value": 440473133
     }
    },
    "a207545455954424b871b0c9d6b0c77c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb16f15aa81c4fdbb4b32c812e23ab89",
       "IPY_MODEL_42e04e9b02fa48779534244842a5c6c7"
      ],
      "layout": "IPY_MODEL_0f38ed5bb47748d39233b34cb4fa55a3"
     }
    },
    "a8cfb4ce32134df2ae156b217d7de3e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba5f40c5de964894a739fee78dd38208": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ce02619fe6354e75b8431dcf84847556": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db97b4da1a804df083f4b393c5cc9bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e378e57b9f2c48abbfaddb116faba4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e1a295942b94359839996e52aa05830",
       "IPY_MODEL_53db219efdf74e57bd629ec214cac13b"
      ],
      "layout": "IPY_MODEL_0fb4adb184b142c8b9561b96ec5a0f56"
     }
    },
    "eb16f15aa81c4fdbb4b32c812e23ab89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17f85ceaf6424513af0c284d1d4c85cb",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ba5f40c5de964894a739fee78dd38208",
      "value": 361
     }
    },
    "f2891d723a69430d9078588a000c5b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
